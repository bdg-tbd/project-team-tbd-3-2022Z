{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBD - etap 2b\n",
    "\n",
    "### Michał Kopyt, Rafał Kulus, Adrian Prorok\n",
    "\n",
    "## Dodatek - pomiary czasu trenowania modeli dla 1 wątku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Inicjalizacja sesji sparkowej, załadowanie bibliotek pyspark, SynapseML oraz pysparkling i połączenie do klastra H2O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting h2o_pysparkling_3.2\n",
      "  Downloading h2o_pysparkling_3.2-3.38.0.4-1.tar.gz (162.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.2/162.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from h2o_pysparkling_3.2) (2.28.1)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->h2o_pysparkling_3.2) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->h2o_pysparkling_3.2) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->h2o_pysparkling_3.2) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->h2o_pysparkling_3.2) (2.1.0)\n",
      "Building wheels for collected packages: h2o_pysparkling_3.2, future\n",
      "  Building wheel for h2o_pysparkling_3.2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for h2o_pysparkling_3.2: filename=h2o_pysparkling_3.2-3.38.0.4.post1-py2.py3-none-any.whl size=162427908 sha256=9eabf8d0664a7b1cf145d297bd987a4c71cc4a5b0a364d6bde8817377092a2e1\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/8d/b1/1a/48d776d100aa559b012748271998372ccae02a056f1362d95c\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491058 sha256=919102ed3ada6b428666ffde848ae78b54b9d53d31bdc0f50c56152eb540d143\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/22/73/06/557dc4f4ef68179b9d763930d6eec26b88ed7c389b19588a1c\n",
      "Successfully built h2o_pysparkling_3.2 future\n",
      "Installing collected packages: tabulate, future, h2o_pysparkling_3.2\n",
      "Successfully installed future-0.18.2 h2o_pysparkling_3.2-3.38.0.4.post1 tabulate-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install h2o_pysparkling_3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 20031999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://018baeb1ba2e:54323 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>09 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.38.0.4</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 day </td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>sparkling-water-jovyan_local-1673057090964</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>891 Mb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://018baeb1ba2e:54323</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>null</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.5 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------\n",
       "H2O_cluster_uptime:         09 secs\n",
       "H2O_cluster_timezone:       Etc/UTC\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.38.0.4\n",
       "H2O_cluster_version_age:    1 day\n",
       "H2O_cluster_name:           sparkling-water-jovyan_local-1673057090964\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    891 Mb\n",
       "H2O_cluster_total_cores:    4\n",
       "H2O_cluster_allowed_cores:  1\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://018baeb1ba2e:54323\n",
       "H2O_connection_proxy:       null\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.5 final\n",
       "--------------------------  ------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.38.0.4-1-3.2\n",
      " * H2O name: sparkling-water-jovyan_local-1673057090964\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (0,172.17.0.2,54321)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://018baeb1ba2e:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.conf import SparkConf\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"tbd1\") \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .config(\"spark.driver.memory\", '1g') \\\n",
    "    .config(\"spark.executor.cores\", 1) \\\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.azure:synapseml_2.12:0.9.5\") \\\n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "from pysparkling import *\n",
    "import h2o\n",
    "hc = H2OContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, month, to_timestamp, hour, regexp_replace\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression, GBTClassifier\n",
    "from pysparkling.ml import H2OGLM, H2OXGBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "from synapse.ml.lightgbm import LightGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ładowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = 'jovyan'\n",
    "\n",
    "# ścieżki dostępu do plików\n",
    "csv_path_1e4 = 'file:////home/jovyan/work/tbd-notebooks/data/ds1-1e4.csv'\n",
    "csv_path_1e5 = 'file:////home/jovyan/work/tbd-notebooks/data/ds1-1e5.csv'\n",
    "csv_path_1e6 = 'file:////home/jovyan/work/tbd-notebooks/data/ds1-1e6.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Przygotowanie funkcji do ładowania i przygotowania danych na podstawie wybranego pliku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_df(csv_path):\n",
    "    df = spark.read.csv(csv_path, inferSchema=True, header=\"true\", nullValue='NA', nanValue='NA',emptyValue='NA')\n",
    "    df = df.filter('Longitude is not NULL and Latitude is not NULL')\n",
    "    df = df.withColumn('label', df.label.cast('integer'))\n",
    "    \n",
    "    df = df.withColumn('Date', to_date(df.Date, 'dd/MM/yyyy'))\n",
    "    df = df.withColumn('Month', month(df.Date))\n",
    "    df = df.withColumn('Time', to_timestamp(df.Time, 'HH:mm'))\n",
    "    df = df.withColumn('Hour', hour(df.Time))\n",
    "    \n",
    "    df = df.withColumn('Light_Conditions', regexp_replace('Light_Conditions', ':', ''))\n",
    "    \n",
    "    df = df.drop('V1', 'Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR', 'Accident_Severity', 'Date', 'Time', 'Local_Authority_(District)', 'Local_Authority_(Highway)', '1st_Road_Number', '2nd_Road_Number', 'LSOA_of_Accident_Location', 'Year')\n",
    "    \n",
    "    columns_for_one_hot_encoding = ['Day_of_Week', '1st_Road_Class', 'Road_Type', 'Junction_Control', '2nd_Road_Class', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions', 'Weather_Conditions', 'Road_Surface_Conditions', 'Special_Conditions_at_Site', 'Carriageway_Hazards', 'Urban_or_Rural_Area', 'Did_Police_Officer_Attend_Scene_of_Accident', 'Month', 'Hour']\n",
    "    other_columns = ['Longitude', 'Latitude', 'Police_Force', 'Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit']\n",
    "\n",
    "    stringindexer_stages = [StringIndexer(inputCol=c, outputCol='stringindexed_' + c).setHandleInvalid(\"keep\") for c in columns_for_one_hot_encoding]\n",
    "    onehotencoder_stages = [OneHotEncoder(inputCol='stringindexed_' + c, outputCol='onehot_' + c) for c in columns_for_one_hot_encoding]\n",
    "\n",
    "    extracted_columns = ['onehot_' + c for c in columns_for_one_hot_encoding]\n",
    "    vectorassembler_stage = VectorAssembler(inputCols=extracted_columns + other_columns, outputCol='features')\n",
    "    \n",
    "    pipeline_stages = stringindexer_stages + onehotencoder_stages + [vectorassembler_stage]\n",
    "    \n",
    "    return Pipeline(stages=pipeline_stages).fit(df).transform(df).select(['features', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowe funkcje do statystyk itp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTestingResults:\n",
    "  def __init__(self, training_time = 0, auc = 0, accuracy = 0, confusion_matrix = None):\n",
    "    self.training_time = training_time\n",
    "    self.auc = auc\n",
    "    self.accuracy = accuracy\n",
    "    self.confusion_matrix = confusion_matrix\n",
    "\n",
    "class ModelTuningResults:\n",
    "  def __init__(self, tuned_params = {}, auc = 0, accuracy = 0, confusion_matrix = None):\n",
    "    self.tuned_params = tuned_params\n",
    "    self.auc = auc\n",
    "    self.accuracy = accuracy\n",
    "    self.confusion_matrix = confusion_matrix\n",
    "\n",
    "def get_confusion_matrix(predictions_df):\n",
    "    return predictions_df.select('label', 'prediction').groupBy('label', 'prediction').count().sort(col('label'), col('prediction')).toPandas()\n",
    "\n",
    "def get_confusion_matrix_sklearn(testing_df, sklearn_pred):\n",
    "    Y_testing = testing_df.select('label').toPandas().to_numpy().ravel()\n",
    "    predictions_df = pd.DataFrame(data={'prediction': sklearn_pred, 'label': Y_testing})\n",
    "    return predictions_df.groupby(['label','prediction'])[['label','prediction']].size().reset_index(name='count').sort_values(by=['label', 'prediction']).reset_index(drop=True)\n",
    "\n",
    "def print_model_testing_results(model_testing_results, label):\n",
    "    if label:\n",
    "        print(f'----- {label} -----')\n",
    "    print(f'Czas trenowania: {round(model_testing_results.training_time, 3)}s')\n",
    "    print(f'AUC: {round(model_testing_results.auc, 3)}')\n",
    "    print(f'Accuracy: {round(model_testing_results.accuracy, 3)}')\n",
    "    print('Macierz pomyłek:')\n",
    "    print(model_testing_results.confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przygotowanie funkcji do testowania modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sparkML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkML_evaluator_auroc = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "sparkML_evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "def test_sparkML(base_model, training_df, testing_df):\n",
    "    training_start_time = timer()\n",
    "    model = base_model.fit(training_df)\n",
    "    training_end_time = timer()\n",
    "    \n",
    "    prediction_df = model.transform(testing_df)\n",
    "    \n",
    "    return ModelTestingResults(\n",
    "        training_time=training_end_time - training_start_time,\n",
    "        auc=sparkML_evaluator_auroc.evaluate(prediction_df),\n",
    "        accuracy=sparkML_evaluator_accuracy.evaluate(prediction_df),\n",
    "        confusion_matrix=get_confusion_matrix(prediction_df)\n",
    "    )\n",
    "\n",
    "def test_sparkML_lr_basic_version(training_df, testing_df):\n",
    "    sparkML_lr = LogisticRegression()\n",
    "    return test_sparkML(sparkML_lr, training_df, testing_df)\n",
    "\n",
    "def test_sparkML_gbt_basic_version(training_df, testing_df):\n",
    "    sparkML_gbt = GBTClassifier()\n",
    "    return test_sparkML(sparkML_gbt, training_df, testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O-sparklinkg-water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_h2o(base_model, training_df, testing_df):\n",
    "    training_start_time = timer()\n",
    "    model = base_model.fit(training_df)\n",
    "    training_end_time = timer()\n",
    "    \n",
    "    prediction_df = model.transform(testing_df)\n",
    "    predicted_labels_for_testing_data = prediction_df.withColumn('prediction', prediction_df.prediction.cast('int')).select('prediction').toPandas().to_numpy().ravel()\n",
    "    labels_for_testing_data = prediction_df.select('label').toPandas().to_numpy().ravel()\n",
    "    probabilities_for_1 = prediction_df.withColumn('detailed_prediction', col('detailed_prediction').probabilities['1']).select('detailed_prediction').toPandas().to_numpy().ravel()\n",
    "    \n",
    "    return ModelTestingResults(\n",
    "        training_time=training_end_time - training_start_time,\n",
    "        auc=roc_auc_score(labels_for_testing_data, probabilities_for_1),\n",
    "        accuracy=accuracy_score(labels_for_testing_data, predicted_labels_for_testing_data),\n",
    "        confusion_matrix=get_confusion_matrix(prediction_df)\n",
    "    )\n",
    "    \n",
    "def test_h2o_lr_basic_version(training_df, testing_df):\n",
    "    h2o_lr = H2OGLM(\n",
    "        family=\"binomial\",\n",
    "        featuresCols=['features'],\n",
    "        labelCol='label'\n",
    "    )\n",
    "    return test_h2o(h2o_lr, training_df, testing_df)\n",
    "\n",
    "def test_h2o_gbt_basic_version(training_df, testing_df):\n",
    "    h2o_gbt = H2OXGBoostClassifier(featuresCols=['features'], labelCol='label')\n",
    "    return test_h2o(h2o_gbt, training_df, testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn (do implementacji nierozproszonej)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "####################################################################################################\n",
    "\n",
    "def test_sklearn_lr_basic_version(training_df, testing_df):\n",
    "    sklearn_lr = SklearnLogisticRegression(n_jobs = 1)\n",
    "    \n",
    "    training_start_time = timer()\n",
    "    features_num = training_df.first().features.size\n",
    "    X = training_df.withColumn('x', vector_to_array('features')).select([col('x')[i] for i in range(features_num)]).toPandas()\n",
    "    y = training_df.select('label').toPandas().to_numpy().ravel()\n",
    "    model = sklearn_lr.fit(X, y)\n",
    "    training_end_time = timer()\n",
    "    \n",
    "    X_testing = testing_df.withColumn('x', vector_to_array('features')).select([col('x')[i] for i in range(features_num)]).toPandas()\n",
    "    y_testing = testing_df.select('label').toPandas().to_numpy().ravel()\n",
    "    prediction_df = model.predict(X_testing)\n",
    "    \n",
    "    return ModelTestingResults(\n",
    "        training_time=training_end_time - training_start_time,\n",
    "        auc=roc_auc_score(y_testing, model.predict_proba(X_testing)[::, 1]),\n",
    "        accuracy=accuracy_score(y_testing, prediction_df),\n",
    "        confusion_matrix=get_confusion_matrix_sklearn(testing_df, prediction_df)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynapseML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_synapseML(base_model, training_df, testing_df):\n",
    "    return test_sparkML(base_model, training_df, testing_df) # Ten sam kod\n",
    "\n",
    "def test_synapseML_gbt_basic_version(training_df, testing_df):\n",
    "    # synapseML_gbt = LightGBMClassifier(objective=\"binary\", featuresCol=\"features\", labelCol=\"label\", isUnbalance=True, numThreads=1)\n",
    "    synapseML_gbt = LightGBMClassifier(objective=\"binary\", featuresCol=\"features\", labelCol=\"label\", numThreads=1)\n",
    "    return test_synapseML(synapseML_gbt, training_df, testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Regresja logistyczna - pomiary czasów trenowania modeli dla różnych zbiorów danych dla 1 wątku**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zbiór danych 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_df_1e4, testing_df_1e4 = get_features_df(csv_path_1e4).randomSplit([0.8, 0.2], seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, sparkML, zbiór 1e4, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 6.338s\n",
      "AUC: 0.646\n",
      "Accuracy: 0.836\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0         0.0      2\n",
      "1      0         1.0    326\n",
      "2      1         0.0      7\n",
      "3      1         1.0   1698\n"
     ]
    }
   ],
   "source": [
    "sparkML_lr_basic_1e4_results = test_sparkML_lr_basic_version(training_df_1e4, testing_df_1e4)\n",
    "\n",
    "label_sparkML_lr_basic_1e4_results = 'Regresja logistyczna, sparkML, zbiór 1e4, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sparkML_lr_basic_1e4_results, label_sparkML_lr_basic_1e4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, H2O-sparkling-water, zbiór 1e4, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 4.0s\n",
      "AUC: 0.646\n",
      "Accuracy: 0.837\n",
      "Macierz pomyłek:\n",
      "   label prediction  count\n",
      "0      0          0      2\n",
      "1      0          1    326\n",
      "2      1          0      6\n",
      "3      1          1   1699\n"
     ]
    }
   ],
   "source": [
    "h2o_lr_basic_1e4_results = test_h2o_lr_basic_version(training_df_1e4, testing_df_1e4)\n",
    "\n",
    "label_h2o_lr_basic_1e4_results = 'Regresja logistyczna, H2O-sparkling-water, zbiór 1e4, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(h2o_lr_basic_1e4_results, label_h2o_lr_basic_1e4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, scikit-learn, zbiór 1e4, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 3.189s\n",
      "AUC: 0.646\n",
      "Accuracy: 0.839\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0           0      3\n",
      "1      0           1    325\n",
      "2      1           0      3\n",
      "3      1           1   1702\n"
     ]
    }
   ],
   "source": [
    "sklearn_lr_basic_1e4_results = test_sklearn_lr_basic_version(training_df_1e4, testing_df_1e4)\n",
    "\n",
    "label_sklearn_lr_basic_1e4_results = 'Regresja logistyczna, scikit-learn, zbiór 1e4, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sklearn_lr_basic_1e4_results, label_sklearn_lr_basic_1e4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zbiór danych 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_1e5, testing_df_1e5 = get_features_df(csv_path_1e5).randomSplit([0.8, 0.2], seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, sparkML, zbiór 1e5, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 11.488s\n",
      "AUC: 0.66\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0         0.0     20\n",
      "1      0         1.0   2958\n",
      "2      1         0.0     12\n",
      "3      1         1.0  17000\n"
     ]
    }
   ],
   "source": [
    "sparkML_lr_basic_1e5_results = test_sparkML_lr_basic_version(training_df_1e5, testing_df_1e5)\n",
    "\n",
    "label_sparkML_lr_basic_1e5_results = 'Regresja logistyczna, sparkML, zbiór 1e5, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sparkML_lr_basic_1e5_results, label_sparkML_lr_basic_1e5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, H2O-sparkling-water, zbiór 1e5, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 9.099s\n",
      "AUC: 0.66\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label prediction  count\n",
      "0      0          0      6\n",
      "1      0          1   2972\n",
      "2      1          0      2\n",
      "3      1          1  17010\n"
     ]
    }
   ],
   "source": [
    "h2o_lr_basic_1e5_results = test_h2o_lr_basic_version(training_df_1e5, testing_df_1e5)\n",
    "\n",
    "label_h2o_lr_basic_1e5_results = 'Regresja logistyczna, H2O-sparkling-water, zbiór 1e5, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(h2o_lr_basic_1e5_results, label_h2o_lr_basic_1e5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, scikit-learn, zbiór 1e5, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 15.391s\n",
      "AUC: 0.657\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0           0     15\n",
      "1      0           1   2963\n",
      "2      1           0     13\n",
      "3      1           1  16999\n"
     ]
    }
   ],
   "source": [
    "sklearn_lr_basic_1e5_results = test_sklearn_lr_basic_version(training_df_1e5, testing_df_1e5)\n",
    "\n",
    "label_sklearn_lr_basic_1e5_results = 'Regresja logistyczna, scikit-learn, zbiór 1e5, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sklearn_lr_basic_1e5_results, label_sklearn_lr_basic_1e5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_1e6, testing_df_1e6 = get_features_df(csv_path_1e6).randomSplit([0.8, 0.2], seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, sparkML, zbiór 1e6, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 57.245s\n",
      "AUC: 0.665\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction   count\n",
      "0      0         0.0     125\n",
      "1      0         1.0   29772\n",
      "2      1         0.0      87\n",
      "3      1         1.0  170211\n"
     ]
    }
   ],
   "source": [
    "sparkML_lr_basic_1e6_results = test_sparkML_lr_basic_version(training_df_1e6, testing_df_1e6)\n",
    "\n",
    "label_sparkML_lr_basic_1e6_results = 'Regresja logistyczna, sparkML, zbiór 1e6, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sparkML_lr_basic_1e6_results, label_sparkML_lr_basic_1e6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, H2O-sparkling-water, zbiór 1e6, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 58.314s\n",
      "AUC: 0.665\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label prediction   count\n",
      "0      0          0      75\n",
      "1      0          1   29822\n",
      "2      1          0      54\n",
      "3      1          1  170244\n"
     ]
    }
   ],
   "source": [
    "h2o_lr_basic_1e6_results = test_h2o_lr_basic_version(training_df_1e6, testing_df_1e6)\n",
    "\n",
    "label_h2o_lr_basic_1e6_results = 'Regresja logistyczna, H2O-sparkling-water, zbiór 1e6, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(h2o_lr_basic_1e6_results, label_h2o_lr_basic_1e6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Regresja logistyczna, scikit-learn, zbiór 1e6, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 119.977s\n",
      "AUC: 0.659\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction   count\n",
      "0      0           0      74\n",
      "1      0           1   29823\n",
      "2      1           0      53\n",
      "3      1           1  170245\n"
     ]
    }
   ],
   "source": [
    "sklearn_lr_basic_1e6_results = test_sklearn_lr_basic_version(training_df_1e6, testing_df_1e6)\n",
    "\n",
    "label_sklearn_lr_basic_1e6_results = 'Regresja logistyczna, scikit-learn, zbiór 1e6, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sklearn_lr_basic_1e6_results, label_sklearn_lr_basic_1e6_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Gradient Boosted Trees - pomiary czasów trenowania modeli dla różnych zbiorów danych dla 1 wątku**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, sparkML, zbiór 1e4, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 10.578s\n",
      "AUC: 0.675\n",
      "Accuracy: 0.837\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0         0.0      3\n",
      "1      0         1.0    325\n",
      "2      1         0.0      7\n",
      "3      1         1.0   1698\n"
     ]
    }
   ],
   "source": [
    "sparkML_gbt_basic_1e4_results = test_sparkML_gbt_basic_version(training_df_1e4, testing_df_1e4)\n",
    "\n",
    "label_sparkML_gbt_basic_1e4_results = 'Gradient Boosted Trees, sparkML, zbiór 1e4, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sparkML_gbt_basic_1e4_results, label_sparkML_gbt_basic_1e4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, H2O-sparkling-water, zbiór 1e4, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 5.903s\n",
      "AUC: 0.655\n",
      "Accuracy: 0.815\n",
      "Macierz pomyłek:\n",
      "   label prediction  count\n",
      "0      0          0     56\n",
      "1      0          1    272\n",
      "2      1          0    104\n",
      "3      1          1   1601\n"
     ]
    }
   ],
   "source": [
    "h2o_gbt_basic_1e4_results = test_h2o_gbt_basic_version(training_df_1e4, testing_df_1e4)\n",
    "\n",
    "label_h2o_gbt_basic_1e4_results = 'Gradient Boosted Trees, H2O-sparkling-water, zbiór 1e4, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(h2o_gbt_basic_1e4_results, label_h2o_gbt_basic_1e4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, SynapseML, zbiór 1e4, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 1.869s\n",
      "AUC: 0.676\n",
      "Accuracy: 0.838\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0         0.0      9\n",
      "1      0         1.0    319\n",
      "2      1         0.0     10\n",
      "3      1         1.0   1695\n"
     ]
    }
   ],
   "source": [
    "synapseML_gbt_basic_1e4_results = test_synapseML_gbt_basic_version(training_df_1e4, testing_df_1e4)\n",
    "\n",
    "label_synapseML_gbt_basic_1e4_results = 'Gradient Boosted Trees, SynapseML, zbiór 1e4, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(synapseML_gbt_basic_1e4_results, label_synapseML_gbt_basic_1e4_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych 1e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, sparkML, zbiór 1e5, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 27.305s\n",
      "AUC: 0.677\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0         0.0     21\n",
      "1      0         1.0   2957\n",
      "2      1         0.0     22\n",
      "3      1         1.0  16990\n"
     ]
    }
   ],
   "source": [
    "sparkML_gbt_basic_1e5_results = test_sparkML_gbt_basic_version(training_df_1e5, testing_df_1e5)\n",
    "\n",
    "label_sparkML_gbt_basic_1e5_results = 'Gradient Boosted Trees, sparkML, zbiór 1e5, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sparkML_gbt_basic_1e5_results, label_sparkML_gbt_basic_1e5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, H2O-sparkling-water, zbiór 1e5, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 17.299s\n",
      "AUC: 0.678\n",
      "Accuracy: 0.845\n",
      "Macierz pomyłek:\n",
      "   label prediction  count\n",
      "0      0          0    200\n",
      "1      0          1   2778\n",
      "2      1          0    313\n",
      "3      1          1  16699\n"
     ]
    }
   ],
   "source": [
    "h2o_gbt_basic_1e5_results = test_h2o_gbt_basic_version(training_df_1e5, testing_df_1e5)\n",
    "\n",
    "label_h2o_gbt_basic_1e5_results = 'Gradient Boosted Trees, H2O-sparkling-water, zbiór 1e5, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(h2o_gbt_basic_1e5_results, label_h2o_gbt_basic_1e5_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, SynapseML, zbiór 1e5, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 8.043s\n",
      "AUC: 0.684\n",
      "Accuracy: 0.852\n",
      "Macierz pomyłek:\n",
      "   label  prediction  count\n",
      "0      0         0.0     35\n",
      "1      0         1.0   2943\n",
      "2      1         0.0     21\n",
      "3      1         1.0  16991\n"
     ]
    }
   ],
   "source": [
    "synapseML_gbt_basic_1e5_results = test_synapseML_gbt_basic_version(training_df_1e5, testing_df_1e5)\n",
    "\n",
    "label_synapseML_gbt_basic_1e5_results = 'Gradient Boosted Trees, SynapseML, zbiór 1e5, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(synapseML_gbt_basic_1e5_results, label_synapseML_gbt_basic_1e5_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiór danych 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, sparkML, zbiór 1e6, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 299.921s\n",
      "AUC: 0.68\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction   count\n",
      "0      0         0.0     144\n",
      "1      0         1.0   29753\n",
      "2      1         0.0      86\n",
      "3      1         1.0  170212\n"
     ]
    }
   ],
   "source": [
    "sparkML_gbt_basic_1e6_results = test_sparkML_gbt_basic_version(training_df_1e6, testing_df_1e6)\n",
    "\n",
    "label_sparkML_gbt_basic_1e6_results = 'Gradient Boosted Trees, sparkML, zbiór 1e6, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(sparkML_gbt_basic_1e6_results, label_sparkML_gbt_basic_1e6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, H2O-sparkling-water, zbiór 1e6, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 137.942s\n",
      "AUC: 0.694\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label prediction   count\n",
      "0      0          0     663\n",
      "1      0          1   29234\n",
      "2      1          0     569\n",
      "3      1          1  169729\n"
     ]
    }
   ],
   "source": [
    "h2o_gbt_basic_1e6_results = test_h2o_gbt_basic_version(training_df_1e6, testing_df_1e6)\n",
    "\n",
    "label_h2o_gbt_basic_1e6_results = 'Gradient Boosted Trees, H2O-sparkling-water, zbiór 1e6, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(h2o_gbt_basic_1e6_results, label_h2o_gbt_basic_1e6_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Gradient Boosted Trees, SynapseML, zbiór 1e6, podstawowe hiperparametry, 1 wątek -----\n",
      "Czas trenowania: 69.243s\n",
      "AUC: 0.694\n",
      "Accuracy: 0.851\n",
      "Macierz pomyłek:\n",
      "   label  prediction   count\n",
      "0      0         0.0     413\n",
      "1      0         1.0   29484\n",
      "2      1         0.0     256\n",
      "3      1         1.0  170042\n"
     ]
    }
   ],
   "source": [
    "synapseML_gbt_basic_1e6_results = test_synapseML_gbt_basic_version(training_df_1e6, testing_df_1e6)\n",
    "\n",
    "label_synapseML_gbt_basic_1e6_results = 'Gradient Boosted Trees, SynapseML, zbiór 1e6, podstawowe hiperparametry, 1 wątek'\n",
    "print_model_testing_results(synapseML_gbt_basic_1e6_results, label_synapseML_gbt_basic_1e6_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "notebook_test": {
   "keytab_path": "/data/work/home/ds-lab-testuser1/ds-lab-testuser1.keytab",
   "user": "ds-lab-testuser1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
